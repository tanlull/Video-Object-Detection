{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.1 : Image classification [Keras model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"details/Residual.png\">\n",
    "# cr. https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "### Standard Library\n",
    "import cv2\n",
    "import time\n",
    "import PIL.Image\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "### Keras Library\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "### TensorRT and Tensorflow Library\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.core.protobuf import config_pb2 as cpb2\n",
    "from tensorflow.python.framework import ops as ops\n",
    "from tensorflow.python.ops import array_ops as aops\n",
    "from tensorflow.python.framework import importer as importer\n",
    "from tensorflow.python.client import session as csess\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Set number of GPUs\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"ResNet50.h5\"\n",
    "infer_model = load_model(model_path)\n",
    "\n",
    "#infer_model = ResNet50(weights='imagenet')\n",
    "#infer_model.save(\"ResNet50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_list = open('imagenet_classes.txt','r')\n",
    "imagenet_label = []\n",
    "\n",
    "for i in imagenet_list:\n",
    "    if len(i)>1:\n",
    "        imagenet_label.append(i.split(\",\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "img_path = 'data/image/piano.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Resize image to 224 x224  \n",
    "img = cv2.resize(img, (224, 224)) \n",
    "\n",
    "# Convert BGR to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Reshape input for 1 batch \n",
    "img = np.reshape(img,[1,224,224,3])\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(img[0])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_time = []\n",
    "for i in range(0,101):\n",
    "    t1 = time.time()\n",
    "    result = infer_model.predict(img)\n",
    "    predict = np.argmax(result)\n",
    "    t2 = time.time()\n",
    "    if i!=0:\n",
    "        k_time.append((t2-t1))\n",
    "        if i%10==0:\n",
    "            print(\"Step %d : %f\" %(i,(t2-t1)))\n",
    "    else:\n",
    "        print(\"Warm up : %f\" %(t2-t1))\n",
    "print(\"Predict time average: %f\" %(sum(k_time)/100.))\n",
    "print(\"Predict class : \"+imagenet_label[predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.2 : Model optimization using TensorRT 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"details/TensorRT4.png\">\n",
    "### cr. https://developer.nvidia.com/tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Keras model (.h5) into Protobuf file (.pb) [tensorflow] \n",
    "\n",
    "!python3 keras_to_tensorflow.py -input_model_file ResNet50.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classification graph def \n",
    "\n",
    "classifier_model_file = 'ResNet50.pb' \n",
    "classifier_graph_def = tf.GraphDef()\n",
    "with tf.gfile.Open(classifier_model_file, 'rb') as f:\n",
    "    data = f.read()\n",
    "    classifier_graph_def.ParseFromString(data)\n",
    "print('Loaded classifier graph def')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TensorRt graph parameter\n",
    "batch_size = 128\n",
    "workspace_size_bytes = 1 << 25\n",
    "trt_gpu_ops = tf.GPUOptions(per_process_gpu_memory_fraction = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open file \"model.ascii\" to get input_node name (first layer) [eg. name: \"input_1\"] and output_node name (last layer) [eg. name: \"output_node0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_graph(gdef, dumm_inp):\n",
    "    \"\"\"Run given graphdef once.\"\"\"\n",
    "    print(\"Executing ...\")\n",
    "    gpu_options = cpb2.GPUOptions(per_process_gpu_memory_fraction=1)\n",
    "    sessconfig = cpb2.ConfigProto(gpu_options=gpu_options)\n",
    "    ops.reset_default_graph()\n",
    "    g = ops.Graph()\n",
    "    keeptime = 0\n",
    "    with g.as_default():\n",
    "        inp, out = importer.import_graph_def(graph_def=gdef, return_elements=[\"input_1:0\", \"output_node0:0\"])\n",
    "    with csess.Session(config=sessconfig, graph=g) as sess:\n",
    "        for i in range(101):\n",
    "            start_time = time.process_time()\n",
    "            val = sess.run([out], {inp: dumm_inp})\n",
    "            stop_time = time.process_time()\n",
    "            if i!=0:\n",
    "                keeptime += stop_time - start_time\n",
    "                if (i%10==0):\n",
    "                    print(\"Step %d : %f seconds\" %(i,(stop_time-start_time)))\n",
    "        nd_result = val[0]\n",
    "        # remove row's dimension\n",
    "        onedim_result = nd_result[0,]\n",
    "        # set column index to array of possibilities \n",
    "        indexed_result = enumerate(onedim_result)\n",
    "        # sort with possibilities\n",
    "        sorted_result = sorted(indexed_result, key=lambda x: x[1], reverse=True)\n",
    "        # get the names of top possibilities\n",
    "        print(\"Predict time average %f seconds\" %((keeptime/100.0)))\n",
    "        for top in sorted_result[:1]:\n",
    "            print(\"Predict class : \"+imagenet_label[top[0]]+\"with confidence: %.3f\" % top[1])\n",
    "    return keeptime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp32_graph = trt.create_inference_graph(\n",
    "      input_graph_def=classifier_graph_def,\n",
    "      outputs=[\"output_node0\"],\n",
    "      max_batch_size=batch_size,\n",
    "      max_workspace_size_bytes=workspace_size_bytes,\n",
    "      precision_mode=\"FP32\",  \n",
    "      )\n",
    "#with gfile.FastGFile(\"resnetV150_TRTFP32.pb\",'wb') as f:\n",
    "    #f.write(fp32_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp32_time = execute_graph(fp32_graph, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp16_graph = trt.create_inference_graph(\n",
    "      input_graph_def=classifier_graph_def,\n",
    "      outputs=[\"output_node0\"],\n",
    "      max_batch_size=batch_size,\n",
    "      max_workspace_size_bytes=workspace_size_bytes,\n",
    "      precision_mode=\"FP16\", \n",
    "      )\n",
    "#with gfile.FastGFile(\"resnetV150_TRTFP16.pb\",'wb') as f:\n",
    "    #f.write(fp16_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp16_time = execute_graph(fp16_graph, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Speed up depend on GPU\n",
    "x = np.arange(3)\n",
    "image_per_sec = [1./(sum(k_time)/100.), 1./(fp32_time/100.), 1./(fp16_time/100.)]\n",
    "\n",
    "\n",
    "def time_sec(x, pos):\n",
    "    'The two args are the value and tick position'\n",
    "    return '% images/sec' % (x)\n",
    "\n",
    "\n",
    "formatter = FuncFormatter(time_sec)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.bar([0,1,2], image_per_sec)\n",
    "plt.xticks(x, ('Keras', 'TensorRT_FP32', 'TensorRT_FP16'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"details/Nvidia_K80.png\">\n",
    "### cr. https://www.nvidia.com/en-us/data-center/tesla-k80/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"details/efficient_RT.png\">\n",
    "### cr. https://devblogs.nvidia.com/wp-content/uploads/2017/04/TensorRT1_perf.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
